{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ea1e896-be70-4c06-9209-8eff02931507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wmin.api import API\n",
    "from validphys.fkparser import load_fktable\n",
    "from super_net.theory_predictions import make_dis_prediction, make_had_prediction, OP\n",
    "\n",
    "from super_net.covmats import sqrt_covmat_jax\n",
    "\n",
    "import jax.scipy.linalg as jla\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import itertools\n",
    "\n",
    "import time\n",
    "import timeit, functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3cb060-c2a4-4778-b762-71d35d770071",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = {\n",
    "    \"dataset_inputs\": [\n",
    "{'dataset':'NMC'},\n",
    "{'dataset': 'SLACP_dwsh'},\n",
    "{'dataset': 'SLACD_dw_ite'},\n",
    "{'dataset': 'BCDMSP_dwsh'},\n",
    "{'dataset': 'BCDMSD_dw_ite'},\n",
    "{'dataset': 'CHORUSNUPb_dw_ite'},\n",
    "{'dataset': 'CHORUSNBPb_dw_ite'},\n",
    "# {'dataset': 'NTVNUDMNFe_dw_ite', 'cfac': ['MAS']},\n",
    "# {'dataset': 'NTVNBDMNFe_dw_ite', 'cfac': ['MAS']},\n",
    "# {'dataset': 'HERACOMBNCEM'} ,\n",
    "# {'dataset': 'HERACOMBNCEP575'},\n",
    "# {'dataset': 'HERACOMBNCEP820'},\n",
    "# {'dataset': 'HERACOMBNCEP920'},\n",
    "# {'dataset': 'HERACOMBNCEP460'},\n",
    "# {'dataset': 'HERACOMBCCEP'},\n",
    "# {'dataset': 'HERACOMBCCEM'} ,\n",
    "# {'dataset':'HERACOMB_SIGMARED_B'},\n",
    "# {'dataset': 'HERACOMB_SIGMARED_C'}\n",
    "                      ],\n",
    "\n",
    "    \"positivity\":{\n",
    "  \"posdatasets\":[\n",
    "  {\"dataset\": \"POSF2U\", \"maxlambda\": 1e6},      # Positivity Lagrange Multiplier\n",
    "  {\"dataset\": \"POSF2DW\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSF2S\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSFLL\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSF2C\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSXUQ\", \"maxlambda\": 1e6},       # Positivity of MSbar PDFs\n",
    "  {\"dataset\": \"POSXUB\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSXDQ\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSXDB\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSXSQ\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSXSB\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSXGL\", \"maxlambda\": 1e6},\n",
    "  {\"dataset\": \"POSDYU\", \"maxlambda\": 1e10},      \n",
    "  {\"dataset\": \"POSDYD\", \"maxlambda\": 1e10},\n",
    "  {\"dataset\": \"POSDYS\", \"maxlambda\": 1e10},\n",
    "    ]\n",
    "    },\n",
    "    \"theoryid\": 400,\n",
    "    \"use_cuts\": \"internal\",\n",
    "    \n",
    "    # wmin basis specs\n",
    "    \"wminpdfset\": \"210623_mnc_disonly_linear_1000\",\n",
    "    \"n_replicas_wmin\": 100,\n",
    "    \n",
    "    # Level 0 closure test\n",
    "    # \"fakedata\": True,\n",
    "    # \"pseudodata\": False, \n",
    "    # \"closure_test_pdf\": \"210623_mnc_disonly_linear_1000\",\n",
    "    \n",
    "    # fit specs\n",
    "    \"use_t0\": True,\n",
    "    \"t0pdfset\": \"210623_mnc_disonly_linear_1000\",\n",
    "    \n",
    "    # \"bayesian_fit\": True,\n",
    "    \"wmin_grid_index\": 1, # random seed used for random parametrisation of wmin pdf\n",
    "#     \"replica_index\": 1,  # random seed used for random noise to central values\n",
    "    \"trval_index\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf0f241-caa1-42ba-b910-dcc01a401b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.5.0 loading all 985 PDFs in set 210623_mnc_disonly_linear_1000\n",
      "210623_mnc_disonly_linear_1000, version 1; 985 PDF members\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 14:03:41.649634: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:606] fastpath_data is none\n",
      "2023-11-21 14:03:41.847687: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:606] fastpath_data is none\n",
      "2023-11-21 14:03:41.878020: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:606] fastpath_data is none\n",
      "2023-11-21 14:03:42.081876: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:606] fastpath_data is none\n",
      "2023-11-21 14:03:42.228008: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:606] fastpath_data is none\n",
      "2023-11-21 14:03:42.228566: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:606] fastpath_data is none\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.5.0 loading /Users/luca/opt/miniconda3/envs/supernet/share/LHAPDF/210623_mnc_disonly_linear_1000/210623_mnc_disonly_linear_1000_0000.dat\n",
      "210623_mnc_disonly_linear_1000 PDF set, member #0, version 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 14:03:53.517587: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:606] fastpath_data is none\n",
      "2023-11-21 14:03:53.645712: E external/org_tensorflow/tensorflow/compiler/xla/python/pjit.cc:606] fastpath_data is none\n"
     ]
    }
   ],
   "source": [
    "weight_minimization_grid = API.weight_minimization_grid(**inp)\n",
    "data_values = API.make_data_values(**inp)\n",
    "pred_data = API.make_pred_data(**inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716351a9-2f82-4f47-bac3-f1165900f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chi2_original(\n",
    "    make_data_values,\n",
    "    make_pred_data,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a jax.jit compiled function that computes the chi2\n",
    "    of a pdf grid on a dataset.\n",
    "\n",
    "    Notes:\n",
    "        - This function is designed for Bayesian like PDF fits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    make_data_values: training_validation.MakeDataValues\n",
    "        dataclass containing data for training and validation.\n",
    "\n",
    "    make_pred_data: theory_predictions.make_pred_data\n",
    "        super_net provider for (fktable) theory predictions.\n",
    "\n",
    "    make_posdata_split: training_validation.PosdataTrainValidationSplit\n",
    "        dataclass inheriting from monte_carlo_utils.TrainValidationSplit\n",
    "\n",
    "    make_penalty_posdata: theory_predictions.make_penalty_posdata\n",
    "        super_net provider used to compute positivity penalty.\n",
    "\n",
    "    alpha: float\n",
    "\n",
    "    lambda_positivity: float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    @jax.jit Callable\n",
    "        function to compute chi2 of a pdf grid.\n",
    "\n",
    "    \"\"\"\n",
    "    training_data = make_data_values.training_data\n",
    "    central_values = training_data.central_values\n",
    "    covmat = training_data.covmat\n",
    "    central_values_idx = training_data.central_values_idx\n",
    "\n",
    "    # sqrt_covmat = jnp.array(sqrt_covmat_jax(covmat))\n",
    "    inv_covmat = jla.inv(covmat)\n",
    "\n",
    "    @jax.jit\n",
    "    def chi2(pdf):\n",
    "        \"\"\" \"\"\"\n",
    "        diff = make_pred_data(pdf)[central_values_idx] - central_values\n",
    "\n",
    "        # sqrt_covmat = jnp.array(sqrt_covmat_jax(covmat))\n",
    "\n",
    "        # solve_triangular: solve the equation a x = b for x, assuming a is a triangular matrix.\n",
    "        # chi2_vec = jla.solve_triangular(sqrt_covmat, diff, lower=True)\n",
    "        # loss = jnp.sum(chi2_vec**2)\n",
    "        loss = jnp.einsum(\"i,ij,j\", diff, inv_covmat, diff)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return chi2\n",
    "\n",
    "chi2_original = make_chi2_original(data_values, pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "358981b6-7b01-4c9c-8dc8-fa8ffe0d9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def log_likelihood(weights):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    wmin_weights = jnp.concatenate((jnp.array([1.0]), weights))\n",
    "    pdf = jnp.einsum(\n",
    "        \"i,ijk\", wmin_weights, weight_minimization_grid.wmin_INPUT_GRID\n",
    "    )\n",
    "    return -0.5 * chi2_original(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5b3d44-d2ec-49cd-82f4-ae1ff0b01be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chi2_opt(make_data_values, make_pred_data):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    training_data = make_data_values.training_data\n",
    "    central_values = training_data.central_values\n",
    "    covmat = training_data.covmat\n",
    "    central_values_idx = training_data.central_values_idx\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(weight_minimization_grid.wmin_INPUT_GRID.shape[0]):\n",
    "        predictions.append(make_pred_data(weight_minimization_grid.wmin_INPUT_GRID[i]))\n",
    "    predictions = jnp.array(predictions)\n",
    "\n",
    "    sqrt_covmat = jnp.array(sqrt_covmat_jax(covmat))\n",
    "\n",
    "    inv_covmat = jla.inv(covmat)\n",
    "\n",
    "    @jax.jit\n",
    "    def chi2(weights):\n",
    "        \"\"\"\n",
    "        TODO\n",
    "        \"\"\"\n",
    "        wmin_weights = jnp.concatenate((jnp.array([1.0]), weights))\n",
    "        theory = jnp.einsum(\n",
    "            \"i,ij\", wmin_weights, predictions\n",
    "        )\n",
    "        diff = (\n",
    "            theory[central_values_idx]\n",
    "            - central_values\n",
    "        )\n",
    "\n",
    "        # solve_triangular: solve the equation a x = b for x, assuming a is a triangular matrix.\n",
    "        # chi2_vec = jla.solve_triangular(sqrt_covmat, diff, lower=True)\n",
    "        # loss = jnp.sum(chi2_vec**2)\n",
    "\n",
    "        loss = jnp.einsum(\"i,ij,j\", diff, inv_covmat, diff)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    return chi2\n",
    "\n",
    "chi2_opt = make_chi2_opt(data_values, pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863a2b65-9667-4a67-81ad-73ff74120593",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def log_likelihood_opt(weights):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    return -0.5 * chi2_opt(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "24e9ebac-81f4-47d8-8e69-08b0025a1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = jax.random.uniform(jax.random.PRNGKey(758493), shape=(10000, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7552456c-a714-4eb4-abd6-656e1533568a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for evalutation: 3.0119669437408447\n"
     ]
    }
   ],
   "source": [
    "chi2s_or = []\n",
    "t0 = time.time()\n",
    "for weight in weights:\n",
    "    chi2s_or.append(log_likelihood(weight))\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "\n",
    "print(\"Time for evalutation:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb21b3c-bdca-476e-907c-5184b379645f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for evalutation: 0.020735979080200195\n"
     ]
    }
   ],
   "source": [
    "chi2s_opt = []\n",
    "t0 = time.time()\n",
    "for weight in weights:\n",
    "    chi2s_opt.append(log_likelihood_opt(weight))\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "\n",
    "print(\"Time for evalutation:\", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078d11e8-be12-41a7-8fc0-d0e20010c637",
   "metadata": {},
   "source": [
    "## Test positivity impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a5806daa-08c8-4770-b287-11dc19b2699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_penalty_posdataset(posdataset):\n",
    "    \"\"\"\n",
    "    Given a PositivitySetSpec compute the positivity penalty\n",
    "    as a lagrange multiplier times elu of minus the theory prediction\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    posdataset : validphys.core.PositivitySetSpec\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    @jax.jit CompiledFunction\n",
    "        Compiled function taking pdf grid and alpha parameter\n",
    "        of jax.nn.elu function in input and returning\n",
    "        elu function evaluated on minus the theory prediction\n",
    "\n",
    "        Note: this is needed in order to compute the positivity\n",
    "        loss function. Elu function is used to avoid a big discontinuity\n",
    "        in the derivative at 0 when the lagrange multiplier is very big.\n",
    "\n",
    "        In practice this function can produce results in the range (-alpha, inf)\n",
    "\n",
    "        see also nnpdf.n3fit.src.layers.losses.LossPositivity\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pred_funcs = []\n",
    "\n",
    "    for fkspec in posdataset.fkspecs:\n",
    "        fk = load_fktable(fkspec).with_cuts(posdataset.cuts)\n",
    "        if fk.hadronic:\n",
    "            pred = make_had_prediction(fk)\n",
    "        else:\n",
    "            pred = make_dis_prediction(fk)\n",
    "        pred_funcs.append(pred)\n",
    "\n",
    "    @jax.jit\n",
    "    def pos_penalty(pdf, alpha, lambda_positivity):\n",
    "        return lambda_positivity * jax.nn.elu(\n",
    "            -OP[posdataset.op](*[f(pdf) for f in pred_funcs]), alpha\n",
    "        )\n",
    "\n",
    "    return pos_penalty\n",
    "\n",
    "\n",
    "def make_penalty_posdata(posdatasets):\n",
    "    \"\"\"\n",
    "    Compute positivity penalty for list of PositivitySetSpec\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    posdatasets: list\n",
    "            list of PositivitySetSpec\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    @jax.jit CompiledFunction\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for posdataset in posdatasets:\n",
    "        predictions.append(make_penalty_posdataset(posdataset))\n",
    "\n",
    "    @jax.jit\n",
    "    def pos_penalties(pdf, alpha, lambda_positivity):\n",
    "        # return predictions[1](pdf, alpha, lambda_positivity)\n",
    "        return jnp.array(\n",
    "            list(\n",
    "                itertools.chain(\n",
    "                    *[f(pdf, alpha, lambda_positivity) for f in predictions[12:]]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return pos_penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "54586ad3-209d-46a3-9846-838dd9975065",
   "metadata": {},
   "outputs": [],
   "source": [
    "posdata_split = API.make_posdata_split(**inp)\n",
    "penalty_posdata = make_penalty_posdata(API.posdatasets(**inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "70f8a0d6-289e-459f-9b70-5ca610bcc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chi2_with_positivity(\n",
    "    make_data_values,\n",
    "    make_pred_data,\n",
    "    make_posdata_split,\n",
    "    make_penalty_posdata,\n",
    "    alpha=1e-7,\n",
    "    lambda_positivity=1000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a jax.jit compiled function that computes the chi2\n",
    "    of a pdf grid on a dataset.\n",
    "\n",
    "    Notes:\n",
    "        - This function is designed for Bayesian like PDF fits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    make_data_values: training_validation.MakeDataValues\n",
    "        dataclass containing data for training and validation.\n",
    "\n",
    "    make_pred_data: theory_predictions.make_pred_data\n",
    "        super_net provider for (fktable) theory predictions.\n",
    "\n",
    "    make_posdata_split: training_validation.PosdataTrainValidationSplit\n",
    "        dataclass inheriting from monte_carlo_utils.TrainValidationSplit\n",
    "\n",
    "    make_penalty_posdata: theory_predictions.make_penalty_posdata\n",
    "        super_net provider used to compute positivity penalty.\n",
    "\n",
    "    alpha: float\n",
    "\n",
    "    lambda_positivity: float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    @jax.jit Callable\n",
    "        function to compute chi2 of a pdf grid.\n",
    "\n",
    "    \"\"\"\n",
    "    training_data = make_data_values.training_data\n",
    "    central_values = training_data.central_values\n",
    "    covmat = training_data.covmat\n",
    "    central_values_idx = training_data.central_values_idx\n",
    "\n",
    "    # Invert the covmat\n",
    "    inv_covmat = jla.inv(covmat)\n",
    "\n",
    "    posdata_training_idx = make_posdata_split.training\n",
    "\n",
    "    @jax.jit\n",
    "    def chi2(pdf):\n",
    "        \"\"\" \"\"\"\n",
    "        diff = make_pred_data(pdf)[central_values_idx] - central_values\n",
    "\n",
    "        loss = jnp.einsum(\"i,ij,j\", diff, inv_covmat, diff)\n",
    "\n",
    "        # add penalty term due to positivity\n",
    "        pos_penalty = make_penalty_posdata(pdf, alpha, lambda_positivity)[\n",
    "            posdata_training_idx\n",
    "        ]\n",
    "        loss += jnp.sum(pos_penalty)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return chi2\n",
    "\n",
    "chi2_withpos = make_chi2_with_positivity(data_values, pred_data, posdata_split, penalty_posdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "44396850-9edd-4432-a4bb-90a331329cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def log_likelihood_withpos(weights):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    wmin_weights = jnp.concatenate((jnp.array([1.0]), weights))\n",
    "    pdf = jnp.einsum(\n",
    "        \"i,ijk\", wmin_weights, weight_minimization_grid.wmin_INPUT_GRID\n",
    "    )\n",
    "    return -0.5 * chi2_withpos(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "255d5562-2ca1-4376-9249-2eec0b457076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for evalutation: 13.286328792572021\n"
     ]
    }
   ],
   "source": [
    "chi2s_withpos = []\n",
    "t0 = time.time()\n",
    "for weight in weights:\n",
    "    chi2s_withpos.append(log_likelihood_withpos(weight))\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "\n",
    "print(\"Time for evalutation:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae91705-7ff1-4f6a-b1d0-f0bfdbcac43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
